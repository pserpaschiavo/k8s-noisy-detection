{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c3f63e32",
   "metadata": {},
   "source": [
    "# Pré-processamento de Dados para Análise de Noisy Neighbors em Kubernetes\n",
    "\n",
    "Este notebook demonstra o processo de carregamento, limpeza e pré-processamento dos dados coletados durante o experimento de detecção de \"noisy neighbors\" em clusters Kubernetes.\n",
    "\n",
    "## Objetivos\n",
    "- Carregar dados de métricas dos diferentes tenants e fases\n",
    "- Limpar e normalizar os dados \n",
    "- Converter timestamps para tempo decorrido\n",
    "- Preparar datasets consolidados para análise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e278a9b",
   "metadata": {},
   "source": [
    "## Configuração Inicial\n",
    "\n",
    "Primeiro, vamos importar as bibliotecas necessárias e configurar o ambiente para análise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33e1322d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importação das bibliotecas\n",
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "import re\n",
    "\n",
    "# Configuração para visualizações de qualidade acadêmica\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (10, 6)\n",
    "plt.rcParams['figure.dpi'] = 300\n",
    "plt.rcParams['font.size'] = 12\n",
    "plt.rcParams['axes.labelsize'] = 14\n",
    "plt.rcParams['axes.titlesize'] = 16\n",
    "plt.rcParams['xtick.labelsize'] = 12\n",
    "plt.rcParams['ytick.labelsize'] = 12\n",
    "plt.rcParams['legend.fontsize'] = 12\n",
    "plt.rcParams['legend.title_fontsize'] = 14\n",
    "\n",
    "# Caminho base para os dados do experimento\n",
    "BASE_DATA_DIR = \"/home/phil/Projects/k8s-noisy-detection/demo-data/demo-experiment-3-rounds\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f1217eb",
   "metadata": {},
   "source": [
    "## Funções de Carregamento de Dados\n",
    "\n",
    "Vamos criar funções flexíveis que permitam carregar dados de diferentes tenants, fases e métricas conforme a necessidade do usuário."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3747cc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_available_tenants(experiment_dir):\n",
    "    \"\"\"\n",
    "    Lista todos os tenants disponíveis no diretório do experimento.\n",
    "    \n",
    "    Args:\n",
    "        experiment_dir (str): Caminho para o diretório do experimento\n",
    "        \n",
    "    Returns:\n",
    "        list: Lista de nomes de tenants\n",
    "    \"\"\"\n",
    "    tenants = set()\n",
    "    \n",
    "    # Procura por diretórios de tenants em todas as fases e rounds\n",
    "    for round_dir in glob.glob(os.path.join(experiment_dir, \"round-*\")):\n",
    "        for phase_dir in glob.glob(os.path.join(round_dir, \"*\")):\n",
    "            # Listamos diretórios dentro de cada fase\n",
    "            for item in os.listdir(phase_dir):\n",
    "                item_path = os.path.join(phase_dir, item)\n",
    "                if os.path.isdir(item_path):\n",
    "                    tenants.add(item)\n",
    "    \n",
    "    return sorted(list(tenants))\n",
    "\n",
    "def list_available_metrics(experiment_dir, tenant=\"tenant-a\"):\n",
    "    \"\"\"\n",
    "    Lista todas as métricas disponíveis para um tenant específico.\n",
    "    \n",
    "    Args:\n",
    "        experiment_dir (str): Caminho para o diretório do experimento\n",
    "        tenant (str): Nome do tenant para listar métricas\n",
    "        \n",
    "    Returns:\n",
    "        list: Lista de nomes de métricas\n",
    "    \"\"\"\n",
    "    metrics = set()\n",
    "    \n",
    "    # Procura arquivos CSV dentro dos diretórios do tenant especificado\n",
    "    pattern = os.path.join(experiment_dir, \"round-*\", \"*\", tenant, \"*.csv\")\n",
    "    for csv_file in glob.glob(pattern):\n",
    "        metric_name = os.path.basename(csv_file).replace(\".csv\", \"\")\n",
    "        metrics.add(metric_name)\n",
    "    \n",
    "    return sorted(list(metrics))\n",
    "\n",
    "def parse_timestamp(timestamp_str):\n",
    "    \"\"\"\n",
    "    Converte string de timestamp no formato usado nos arquivos CSV para objeto datetime.\n",
    "    \n",
    "    Args:\n",
    "        timestamp_str (str): String de timestamp no formato \"YYYYMMDD_HHMMSS\"\n",
    "        \n",
    "    Returns:\n",
    "        datetime: Objeto datetime correspondente\n",
    "    \"\"\"\n",
    "    return datetime.strptime(timestamp_str, \"%Y%m%d_%H%M%S\")\n",
    "\n",
    "def load_metric_data(experiment_dir, metric_name, tenants=None, phases=None, rounds=None):\n",
    "    \"\"\"\n",
    "    Carrega dados de uma métrica específica para os tenants, fases e rounds selecionados.\n",
    "    \n",
    "    Args:\n",
    "        experiment_dir (str): Caminho para o diretório do experimento\n",
    "        metric_name (str): Nome da métrica a ser carregada\n",
    "        tenants (list): Lista de tenants a incluir (None = todos)\n",
    "        phases (list): Lista de fases a incluir (None = todas)\n",
    "        rounds (list): Lista de rounds a incluir (None = todos)\n",
    "        \n",
    "    Returns:\n",
    "        DataFrame: DataFrame consolidado com os dados da métrica\n",
    "    \"\"\"\n",
    "    all_data = []\n",
    "    \n",
    "    # Se nenhuma lista específica for fornecida, incluir tudo\n",
    "    if tenants is None:\n",
    "        tenants = list_available_tenants(experiment_dir)\n",
    "    if rounds is None:\n",
    "        rounds = [f\"round-{i}\" for i in range(1, 10)]  # Assume até 9 rounds\n",
    "        rounds = [r for r in rounds if os.path.exists(os.path.join(experiment_dir, r))]\n",
    "    if phases is None:\n",
    "        phases = [\"*\"]  # Glob pattern para pegar todas as fases\n",
    "    \n",
    "    for round_name in rounds:\n",
    "        for phase_pattern in phases:\n",
    "            phase_dirs = glob.glob(os.path.join(experiment_dir, round_name, phase_pattern))\n",
    "            \n",
    "            for phase_dir in phase_dirs:\n",
    "                phase_name = os.path.basename(phase_dir)\n",
    "                # Extrai o número da fase\n",
    "                phase_number = re.search(r'^(\\d+)', phase_name)\n",
    "                phase_number = int(phase_number.group(1)) if phase_number else 0\n",
    "                \n",
    "                for tenant in tenants:\n",
    "                    csv_path = os.path.join(phase_dir, tenant, f\"{metric_name}.csv\")\n",
    "                    \n",
    "                    if os.path.exists(csv_path):\n",
    "                        try:\n",
    "                            df = pd.read_csv(csv_path)\n",
    "                            \n",
    "                            # Adicionar metadados\n",
    "                            df['tenant'] = tenant\n",
    "                            df['round'] = round_name\n",
    "                            df['phase'] = phase_name\n",
    "                            df['phase_number'] = phase_number\n",
    "                            \n",
    "                            # Converter timestamp para datetime\n",
    "                            df['datetime'] = df['timestamp'].apply(parse_timestamp)\n",
    "                            \n",
    "                            all_data.append(df)\n",
    "                        except Exception as e:\n",
    "                            print(f\"Erro ao carregar {csv_path}: {e}\")\n",
    "    \n",
    "    if not all_data:\n",
    "        return pd.DataFrame()\n",
    "    \n",
    "    return pd.concat(all_data, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a89da6fe",
   "metadata": {},
   "source": [
    "## Normalização do Tempo\n",
    "\n",
    "Para facilitar a análise entre diferentes fases e rounds, vamos converter os timestamps absolutos para tempo decorrido desde o início de cada fase ou do experimento completo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4022bc63",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_elapsed_time(df, group_by=['round', 'phase']):\n",
    "    \"\"\"\n",
    "    Adiciona colunas de tempo decorrido, calculado desde o início de cada grupo.\n",
    "    \n",
    "    Args:\n",
    "        df (DataFrame): DataFrame com dados do experimento\n",
    "        group_by (list): Colunas para agrupar ao calcular tempo inicial\n",
    "        \n",
    "    Returns:\n",
    "        DataFrame: DataFrame com colunas adicionais de tempo decorrido\n",
    "    \"\"\"\n",
    "    # Cria uma cópia para não modificar o original\n",
    "    result = df.copy()\n",
    "    \n",
    "    # Encontrar o timestamp inicial para cada grupo\n",
    "    start_times = df.groupby(group_by)['datetime'].min().reset_index()\n",
    "    \n",
    "    # Renomear a coluna para facilitar o merge\n",
    "    start_times = start_times.rename(columns={'datetime': 'start_time'})\n",
    "    \n",
    "    # Mesclar com o DataFrame original\n",
    "    result = pd.merge(result, start_times, on=group_by)\n",
    "    \n",
    "    # Calcular tempo decorrido em segundos desde o início de cada grupo\n",
    "    result['elapsed_seconds'] = (result['datetime'] - result['start_time']).dt.total_seconds()\n",
    "    \n",
    "    # Calcular tempo decorrido em minutos (para facilitar a visualização)\n",
    "    result['elapsed_minutes'] = result['elapsed_seconds'] / 60.0\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b975cb2",
   "metadata": {},
   "source": [
    "## Exploração dos Dados Disponíveis\n",
    "\n",
    "Vamos listar os tenants e métricas disponíveis no nosso conjunto de dados para entender melhor o que temos à disposição."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e228b96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Listar tenants disponíveis\n",
    "tenants = list_available_tenants(BASE_DATA_DIR)\n",
    "print(f\"Tenants disponíveis: {tenants}\")\n",
    "\n",
    "# Listar métricas disponíveis para um tenant\n",
    "metrics = list_available_metrics(BASE_DATA_DIR)\n",
    "print(f\"\\nMétricas disponíveis: {metrics}\")\n",
    "\n",
    "# Listar rounds disponíveis\n",
    "rounds = [d for d in os.listdir(BASE_DATA_DIR) if os.path.isdir(os.path.join(BASE_DATA_DIR, d)) and d.startswith(\"round-\")]\n",
    "print(f\"\\nRounds disponíveis: {rounds}\")\n",
    "\n",
    "# Listar fases para o primeiro round (como exemplo)\n",
    "phases = [d for d in os.listdir(os.path.join(BASE_DATA_DIR, rounds[0])) if os.path.isdir(os.path.join(BASE_DATA_DIR, rounds[0], d))]\n",
    "print(f\"\\nFases disponíveis (para {rounds[0]}): {phases}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0bcc13d",
   "metadata": {},
   "source": [
    "## Análise de uma Métrica Específica\n",
    "\n",
    "Vamos carregar os dados de uso de CPU para todos os tenants e visualizar como essa métrica se comporta ao longo das fases do experimento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "376c5ae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carregar dados de CPU para todos os tenants\n",
    "cpu_data = load_metric_data(BASE_DATA_DIR, \"cpu_usage\")\n",
    "\n",
    "# Adicionar tempo decorrido\n",
    "cpu_data = add_elapsed_time(cpu_data)\n",
    "\n",
    "# Verificar os dados carregados\n",
    "print(f\"Dimensões do DataFrame: {cpu_data.shape}\")\n",
    "cpu_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cbf4d08",
   "metadata": {},
   "source": [
    "## Visualização do Uso de CPU por Tenant\n",
    "\n",
    "Vamos criar um gráfico que mostra o uso de CPU para cada tenant ao longo das fases do experimento para o primeiro round."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d94c1b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtrar para o primeiro round\n",
    "round1_data = cpu_data[cpu_data['round'] == 'round-1'].copy()\n",
    "\n",
    "# Criar um gráfico para cada fase\n",
    "phases = sorted(round1_data['phase'].unique())\n",
    "\n",
    "plt.figure(figsize=(15, 10))\n",
    "\n",
    "for i, phase in enumerate(phases):\n",
    "    plt.subplot(len(phases), 1, i+1)\n",
    "    \n",
    "    # Filtrar dados para esta fase\n",
    "    phase_data = round1_data[round1_data['phase'] == phase]\n",
    "    \n",
    "    # Plotar dados para cada tenant\n",
    "    for tenant in sorted(phase_data['tenant'].unique()):\n",
    "        tenant_data = phase_data[phase_data['tenant'] == tenant]\n",
    "        plt.plot(tenant_data['elapsed_minutes'], tenant_data['value'], label=tenant)\n",
    "    \n",
    "    plt.title(f\"Fase: {phase}\")\n",
    "    plt.xlabel(\"Tempo Decorrido (minutos)\")\n",
    "    plt.ylabel(\"Uso de CPU\")\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba2d6513",
   "metadata": {},
   "source": [
    "## Análise Comparativa entre Fases\n",
    "\n",
    "Vamos calcular estatísticas resumidas para comparar o uso de CPU entre diferentes fases para cada tenant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4a9407e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcular estatísticas por tenant e fase\n",
    "summary_stats = cpu_data.groupby(['tenant', 'round', 'phase']).agg({\n",
    "    'value': ['mean', 'std', 'min', 'max', 'count']\n",
    "}).reset_index()\n",
    "\n",
    "# Renomear as colunas para facilitar o acesso\n",
    "summary_stats.columns = ['tenant', 'round', 'phase', 'mean_cpu', 'std_cpu', 'min_cpu', 'max_cpu', 'count']\n",
    "\n",
    "# Ordenar por tenant, round e fase\n",
    "summary_stats = summary_stats.sort_values(['tenant', 'round', 'phase_number'])\n",
    "\n",
    "# Visualizar as estatísticas\n",
    "summary_stats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e913b59",
   "metadata": {},
   "source": [
    "## Visualização Comparativa entre Fases\n",
    "\n",
    "Vamos criar um gráfico de barras que compara o uso médio de CPU entre as diferentes fases para cada tenant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38bd80e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criar gráfico comparativo\n",
    "plt.figure(figsize=(14, 8))\n",
    "\n",
    "# Agrupar por tenant e fase para o primeiro round\n",
    "summary_round1 = summary_stats[summary_stats['round'] == 'round-1']\n",
    "\n",
    "# Normalizar os nomes das fases para exibição no gráfico\n",
    "summary_round1['phase_name'] = summary_round1['phase'].apply(lambda x: x.split('-')[-1].strip())\n",
    "\n",
    "# Pivotear os dados para facilitar a plotagem\n",
    "pivot_data = summary_round1.pivot(index='tenant', columns='phase_name', values='mean_cpu')\n",
    "\n",
    "# Criar gráfico de barras\n",
    "ax = pivot_data.plot(kind='bar', figsize=(14, 8))\n",
    "plt.title('Uso Médio de CPU por Tenant em Diferentes Fases (Round 1)')\n",
    "plt.xlabel('Tenant')\n",
    "plt.ylabel('Uso Médio de CPU')\n",
    "plt.legend(title='Fase')\n",
    "plt.grid(axis='y')\n",
    "\n",
    "# Adicionar valores sobre as barras\n",
    "for container in ax.containers:\n",
    "    ax.bar_label(container, fmt='%.2f', padding=3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "328ac976",
   "metadata": {},
   "source": [
    "## Exportação de Tabelas para Publicações Acadêmicas\n",
    "\n",
    "Vamos demonstrar como exportar os resultados em formatos adequados para publicações acadêmicas (.csv e .tex)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b08089b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exportar para CSV\n",
    "summary_stats.to_csv('cpu_usage_summary.csv', index=False)\n",
    "print(\"Tabela exportada como CSV\")\n",
    "\n",
    "# Função para exportar para LaTeX\n",
    "def export_to_latex(df, caption, label, filename):\n",
    "    \"\"\"\n",
    "    Exporta um DataFrame para uma tabela LaTeX formatada.\n",
    "    \n",
    "    Args:\n",
    "        df (DataFrame): DataFrame a ser exportado\n",
    "        caption (str): Legenda da tabela\n",
    "        label (str): Identificador para referência cruzada\n",
    "        filename (str): Nome do arquivo de saída\n",
    "    \"\"\"\n",
    "    latex_table = df.to_latex(index=False, caption=caption, label=label, float_format=\"%.2f\")\n",
    "    \n",
    "    # Adicionar pacotes e formatação adicional\n",
    "    latex_preamble = \"\"\"\\\\documentclass{article}\n",
    "\\\\usepackage{booktabs}\n",
    "\\\\usepackage{siunitx}\n",
    "\\\\usepackage{caption}\n",
    "\\\\begin{document}\n",
    "\"\"\"\n",
    "    latex_end = \"\\\\end{document}\"\n",
    "    \n",
    "    with open(filename, 'w') as f:\n",
    "        f.write(latex_preamble)\n",
    "        f.write(latex_table)\n",
    "        f.write(latex_end)\n",
    "    \n",
    "    print(f\"Tabela exportada como LaTeX para {filename}\")\n",
    "\n",
    "# Exportar para LaTeX\n",
    "export_to_latex(\n",
    "    summary_stats[summary_stats['round'] == 'round-1'], \n",
    "    \"Estatísticas de uso de CPU por tenant e fase no Round 1\",\n",
    "    \"tab:cpu_usage_round1\",\n",
    "    \"cpu_usage_round1.tex\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d1fe291",
   "metadata": {},
   "source": [
    "## Conclusão e Próximos Passos\n",
    "\n",
    "Neste notebook, demonstramos:\n",
    "\n",
    "1. Como carregar e consolidar dados de diferentes tenants e fases\n",
    "2. Como normalizar os timestamps para tempo decorrido\n",
    "3. Como visualizar o uso de CPU ao longo das fases do experimento\n",
    "4. Como calcular estatísticas comparativas entre fases e tenants\n",
    "5. Como exportar resultados em formatos adequados para publicações acadêmicas\n",
    "\n",
    "No próximo notebook, vamos explorar análises mais avançadas, incluindo:\n",
    "- Correlações entre diferentes métricas\n",
    "- Detecção de anomalias e padrões\n",
    "- Análise de impacto do \"noisy neighbor\" nos demais tenants\n",
    "\n",
    "Também vamos criar visualizações mais elaboradas que destacam claramente o fenômeno de \"noisy neighbor\" no ambiente Kubernetes."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
