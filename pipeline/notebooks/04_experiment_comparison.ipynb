{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e856e9fe",
   "metadata": {},
   "source": [
    "# Comparação entre Experimentos de Noisy Neighbors\n",
    "\n",
    "Este notebook demonstra como comparar diferentes experimentos de noisy neighbors para identificar padrões, diferenças e semelhanças entre configurações experimentais."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4f3a279",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "from scipy import stats\n",
    "\n",
    "# Ajustar o path para importar os módulos do pipeline\n",
    "sys.path.append(os.path.abspath('../..'))\n",
    "\n",
    "# Importar módulos necessários do pipeline\n",
    "from pipeline.data_processing.consolidation import load_experiment_data, select_tenants\n",
    "from pipeline.data_processing.time_normalization import normalize_time\n",
    "from pipeline.data_processing.aggregation import aggregate_by_time\n",
    "from pipeline.analysis.advanced_analysis import calculate_covariance_matrix, calculate_entropy_metrics\n",
    "from pipeline.analysis.phase_analysis import compare_phases\n",
    "from pipeline.analysis.anomaly_detection import detect_anomalies_ensemble\n",
    "from pipeline.visualization.plots import plot_comparison, create_heatmap\n",
    "\n",
    "# Configurar visualização\n",
    "plt.style.use('ggplot')\n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "plt.rcParams['figure.figsize'] = [12, 6]\n",
    "plt.rcParams['figure.dpi'] = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19abfc76",
   "metadata": {},
   "source": [
    "## 1. Carregar Dados de Múltiplos Experimentos\n",
    "\n",
    "Primeiro, vamos carregar dados de diferentes experimentos para comparação."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75830564",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir caminhos para diferentes experimentos\n",
    "experiment_paths = [\n",
    "    '../../demo-data/demo-experiment-3-rounds/',\n",
    "    # Adicionar caminhos para outros experimentos conforme necessário\n",
    "]\n",
    "\n",
    "# Carregar dados de cada experimento\n",
    "experiments = {}\n",
    "for i, path in enumerate(experiment_paths):\n",
    "    try:\n",
    "        metrics_data, exp_info = load_experiment_data(path)\n",
    "        \n",
    "        # Usar o nome do experimento se disponível, caso contrário usar um ID\n",
    "        exp_name = exp_info.get('name', f'experiment_{i+1}')\n",
    "        \n",
    "        # Armazenar dados e metadados\n",
    "        experiments[exp_name] = {\n",
    "            'metrics': metrics_data,\n",
    "            'info': exp_info\n",
    "        }\n",
    "        \n",
    "        print(f\"Carregado experimento: {exp_name}\")\n",
    "        print(f\"  - Métricas: {list(metrics_data.keys())}\")\n",
    "        print(f\"  - Tenants: {exp_info.get('tenants', [])}\")\n",
    "        print(f\"  - Fases: {exp_info.get('phases', [])}\")\n",
    "        print()\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Erro ao carregar experimento em {path}: {str(e)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "425c36a1",
   "metadata": {},
   "source": [
    "## 2. Preparar Dados para Comparação\n",
    "\n",
    "Vamos preparar os dados para comparar experimentos, normalizando o tempo e selecionando métricas de interesse."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e98751f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Métricas de interesse para comparação\n",
    "metrics_of_interest = ['cpu_usage', 'memory_usage']\n",
    "\n",
    "# Preprocessar dados para cada experimento\n",
    "for exp_name, exp_data in experiments.items():\n",
    "    # Filtrar métricas de interesse\n",
    "    selected_metrics = {k: v for k, v in exp_data['metrics'].items() if k in metrics_of_interest}\n",
    "    \n",
    "    # Normalizar tempo para cada métrica\n",
    "    normalized_metrics = {}\n",
    "    for metric_name, df in selected_metrics.items():\n",
    "        # Normalizar tempo\n",
    "        norm_df = normalize_time(df, exp_data['info'])\n",
    "        \n",
    "        # Adicionar coluna de tempo decorrido em minutos\n",
    "        norm_df['elapsed_minutes'] = (norm_df['datetime'] - norm_df['datetime'].min()).dt.total_seconds() / 60\n",
    "        \n",
    "        # Agregar dados por minuto para uniformizar comparações\n",
    "        agg_df = aggregate_by_time(norm_df, time_column='elapsed_minutes', freq='1min')\n",
    "        \n",
    "        normalized_metrics[metric_name] = agg_df\n",
    "    \n",
    "    # Atualizar dados do experimento\n",
    "    exp_data['processed_metrics'] = normalized_metrics\n",
    "\n",
    "# Verificar uma amostra dos dados processados\n",
    "if experiments:\n",
    "    exp_name = list(experiments.keys())[0]\n",
    "    for metric in metrics_of_interest:\n",
    "        if metric in experiments[exp_name]['processed_metrics']:\n",
    "            print(f\"Amostra de {metric} para {exp_name}:\")\n",
    "            display(experiments[exp_name]['processed_metrics'][metric].head())\n",
    "            print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5fd0cff",
   "metadata": {},
   "source": [
    "## 3. Comparação de Estatísticas Básicas entre Experimentos\n",
    "\n",
    "Vamos comparar estatísticas básicas (média, mediana, desvio padrão, etc.) entre experimentos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d48beef6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função para calcular estatísticas resumidas\n",
    "def calculate_statistics(df, metric_column='value', group_by=None):\n",
    "    if group_by:\n",
    "        stats_df = df.groupby(group_by)[metric_column].agg([\n",
    "            ('média', 'mean'),\n",
    "            ('mediana', 'median'),\n",
    "            ('desvio_padrao', 'std'),\n",
    "            ('mínimo', 'min'),\n",
    "            ('máximo', 'max'),\n",
    "            ('contagem', 'count')\n",
    "        ])\n",
    "    else:\n",
    "        stats_df = pd.DataFrame({\n",
    "            'média': [df[metric_column].mean()],\n",
    "            'mediana': [df[metric_column].median()],\n",
    "            'desvio_padrao': [df[metric_column].std()],\n",
    "            'mínimo': [df[metric_column].min()],\n",
    "            'máximo': [df[metric_column].max()],\n",
    "            'contagem': [df[metric_column].count()]\n",
    "        })\n",
    "    \n",
    "    return stats_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dd8d7cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparar estatísticas básicas entre experimentos\n",
    "for metric in metrics_of_interest:\n",
    "    print(f\"Comparação de estatísticas para {metric}:\\n\")\n",
    "    \n",
    "    # Criar DataFrame para comparação\n",
    "    all_stats = []\n",
    "    \n",
    "    # Calcular estatísticas para cada experimento\n",
    "    for exp_name, exp_data in experiments.items():\n",
    "        if metric in exp_data['processed_metrics']:\n",
    "            # Estatísticas globais\n",
    "            df = exp_data['processed_metrics'][metric]\n",
    "            stats_df = calculate_statistics(df)\n",
    "            stats_df['experimento'] = exp_name\n",
    "            stats_df['grupo'] = 'global'\n",
    "            all_stats.append(stats_df)\n",
    "            \n",
    "            # Estatísticas por tenant\n",
    "            tenant_stats = calculate_statistics(df, group_by=['tenant'])\n",
    "            tenant_stats = tenant_stats.reset_index()\n",
    "            tenant_stats['experimento'] = exp_name\n",
    "            tenant_stats['grupo'] = tenant_stats['tenant']\n",
    "            all_stats.append(tenant_stats)\n",
    "            \n",
    "            # Estatísticas por fase\n",
    "            phase_stats = calculate_statistics(df, group_by=['phase'])\n",
    "            phase_stats = phase_stats.reset_index()\n",
    "            phase_stats['experimento'] = exp_name\n",
    "            phase_stats['grupo'] = phase_stats['phase']\n",
    "            all_stats.append(phase_stats)\n",
    "    \n",
    "    # Consolidar estatísticas\n",
    "    if all_stats:\n",
    "        combined_stats = pd.concat(all_stats, ignore_index=True)\n",
    "        \n",
    "        # Pivotar para facilitar comparação entre experimentos\n",
    "        pivot_stats = combined_stats.pivot_table(\n",
    "            index=['grupo'],\n",
    "            columns=['experimento'],\n",
    "            values=['média', 'mediana', 'desvio_padrao', 'máximo']\n",
    "        )\n",
    "        \n",
    "        # Exibir estatísticas comparativas\n",
    "        display(pivot_stats)\n",
    "        print(\"\\n\" + \"-\"*80 + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1425ce12",
   "metadata": {},
   "source": [
    "## 4. Comparação de Distribuições entre Experimentos\n",
    "\n",
    "Vamos visualizar e comparar as distribuições de métricas entre experimentos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2e595c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função para comparar distribuições de métricas entre experimentos\n",
    "def compare_distributions(experiments, metric, tenant=None, phase=None):\n",
    "    plt.figure(figsize=(14, 6))\n",
    "    \n",
    "    # Organizar dados para comparação\n",
    "    data_to_plot = []\n",
    "    labels = []\n",
    "    \n",
    "    for exp_name, exp_data in experiments.items():\n",
    "        if metric in exp_data['processed_metrics']:\n",
    "            df = exp_data['processed_metrics'][metric]\n",
    "            \n",
    "            # Filtrar por tenant ou fase se especificados\n",
    "            if tenant:\n",
    "                df = df[df['tenant'] == tenant]\n",
    "            if phase:\n",
    "                df = df[df['phase'] == phase]\n",
    "            \n",
    "            if not df.empty:\n",
    "                data_to_plot.append(df['value'])\n",
    "                labels.append(exp_name)\n",
    "    \n",
    "    if not data_to_plot:\n",
    "        return \"Dados insuficientes para comparação\"\n",
    "    \n",
    "    # Plotar distribuições (boxplot)\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.boxplot(data_to_plot, labels=labels)\n",
    "    plt.title(f'Boxplot de {metric}' + \n",
    "             (f' para {tenant}' if tenant else '') + \n",
    "             (f' na fase {phase}' if phase else ''))\n",
    "    plt.ylabel('Valor')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Plotar distribuições (violin plot)\n",
    "    plt.subplot(1, 2, 2)\n",
    "    for i, data in enumerate(data_to_plot):\n",
    "        plt.violinplot(data, positions=[i+1])\n",
    "    plt.title(f'Violin Plot de {metric}' + \n",
    "             (f' para {tenant}' if tenant else '') + \n",
    "             (f' na fase {phase}' if phase else ''))\n",
    "    plt.ylabel('Valor')\n",
    "    plt.xticks(range(1, len(labels)+1), labels, rotation=45)\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Executar teste estatístico para comparar distribuições\n",
    "    if len(data_to_plot) >= 2:\n",
    "        print(\"Comparações estatísticas:\")\n",
    "        for i in range(len(data_to_plot)):\n",
    "            for j in range(i+1, len(data_to_plot)):\n",
    "                # Kolmogorov-Smirnov test\n",
    "                ks_stat, ks_pval = stats.ks_2samp(data_to_plot[i], data_to_plot[j])\n",
    "                \n",
    "                # Mann-Whitney U test\n",
    "                u_stat, u_pval = stats.mannwhitneyu(data_to_plot[i], data_to_plot[j], \n",
    "                                                   alternative='two-sided')\n",
    "                \n",
    "                print(f\"\\n{labels[i]} vs {labels[j]}:\")\n",
    "                print(f\"  Kolmogorov-Smirnov test: statistic={ks_stat:.4f}, p-value={ks_pval:.4f}\")\n",
    "                print(f\"  Mann-Whitney U test: statistic={u_stat:.4f}, p-value={u_pval:.4f}\")\n",
    "                \n",
    "                if ks_pval < 0.05:\n",
    "                    print(\"  Conclusão K-S: As distribuições são significativamente diferentes\")\n",
    "                else:\n",
    "                    print(\"  Conclusão K-S: Não há evidência suficiente de que as distribuições são diferentes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d3ea228",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparar distribuições para cada métrica\n",
    "for metric in metrics_of_interest:\n",
    "    print(f\"\\n{'-'*40} Comparação de {metric} {'-'*40}\\n\")\n",
    "    \n",
    "    # Comparação global\n",
    "    print(\"\\nComparação global:\")\n",
    "    compare_distributions(experiments, metric)\n",
    "    \n",
    "    # Comparação para tenant específico (se houver dados suficientes)\n",
    "    common_tenants = []\n",
    "    for exp_data in experiments.values():\n",
    "        if 'tenants' in exp_data['info']:\n",
    "            if not common_tenants:\n",
    "                common_tenants = exp_data['info']['tenants']\n",
    "            else:\n",
    "                common_tenants = [t for t in common_tenants if t in exp_data['info']['tenants']]\n",
    "    \n",
    "    if common_tenants:\n",
    "        print(f\"\\nComparação para tenant {common_tenants[0]}:\")\n",
    "        compare_distributions(experiments, metric, tenant=common_tenants[0])\n",
    "    \n",
    "    # Comparação para fase específica (se houver dados suficientes)\n",
    "    common_phases = []\n",
    "    for exp_data in experiments.values():\n",
    "        if 'phases' in exp_data['info']:\n",
    "            if not common_phases:\n",
    "                common_phases = exp_data['info']['phases']\n",
    "            else:\n",
    "                common_phases = [p for p in common_phases if p in exp_data['info']['phases']]\n",
    "    \n",
    "    if common_phases:\n",
    "        print(f\"\\nComparação para fase {common_phases[0]}:\")\n",
    "        compare_distributions(experiments, metric, phase=common_phases[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a06ec32a",
   "metadata": {},
   "source": [
    "## 5. Comparação de Anomalias entre Experimentos\n",
    "\n",
    "Vamos comparar a prevalência e os tipos de anomalias detectadas em diferentes experimentos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab1096f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detectar anomalias em cada experimento\n",
    "anomaly_results = {}\n",
    "\n",
    "for exp_name, exp_data in experiments.items():\n",
    "    anomaly_results[exp_name] = {}\n",
    "    \n",
    "    for metric in metrics_of_interest:\n",
    "        if metric in exp_data['processed_metrics']:\n",
    "            df = exp_data['processed_metrics'][metric]\n",
    "            \n",
    "            # Detectar anomalias\n",
    "            df_with_anomalies, _ = detect_anomalies_ensemble(\n",
    "                df, \n",
    "                metric_column='value',\n",
    "                time_column='elapsed_minutes',\n",
    "                contamination=0.05,\n",
    "                group_by=['tenant']\n",
    "            )\n",
    "            \n",
    "            # Armazenar resultados\n",
    "            anomaly_results[exp_name][metric] = df_with_anomalies\n",
    "\n",
    "# Resumir resultados de anomalias por experimento\n",
    "anomaly_summary = []\n",
    "\n",
    "for exp_name, metrics_results in anomaly_results.items():\n",
    "    for metric, df in metrics_results.items():\n",
    "        # Estatísticas globais\n",
    "        total_points = len(df)\n",
    "        anomaly_if_count = df['is_anomaly_if'].sum()\n",
    "        anomaly_lof_count = df['is_anomaly_lof'].sum()\n",
    "        anomaly_ensemble_count = df['is_anomaly'].sum() if 'is_anomaly' in df.columns else 0\n",
    "        change_point_count = df['is_change_point'].sum() if 'is_change_point' in df.columns else 0\n",
    "        \n",
    "        anomaly_summary.append({\n",
    "            'experimento': exp_name,\n",
    "            'métrica': metric,\n",
    "            'grupo': 'global',\n",
    "            'total_pontos': total_points,\n",
    "            'anomalias_if': anomaly_if_count,\n",
    "            'anomalias_lof': anomaly_lof_count,\n",
    "            'anomalias_ensemble': anomaly_ensemble_count,\n",
    "            'pontos_mudanca': change_point_count,\n",
    "            'pct_anomalias': (anomaly_ensemble_count / total_points * 100) if total_points > 0 else 0\n",
    "        })\n",
    "        \n",
    "        # Estatísticas por tenant\n",
    "        for tenant in df['tenant'].unique():\n",
    "            tenant_df = df[df['tenant'] == tenant]\n",
    "            total_points = len(tenant_df)\n",
    "            anomaly_if_count = tenant_df['is_anomaly_if'].sum()\n",
    "            anomaly_lof_count = tenant_df['is_anomaly_lof'].sum()\n",
    "            anomaly_ensemble_count = tenant_df['is_anomaly'].sum() if 'is_anomaly' in tenant_df.columns else 0\n",
    "            change_point_count = tenant_df['is_change_point'].sum() if 'is_change_point' in tenant_df.columns else 0\n",
    "            \n",
    "            anomaly_summary.append({\n",
    "                'experimento': exp_name,\n",
    "                'métrica': metric,\n",
    "                'grupo': tenant,\n",
    "                'total_pontos': total_points,\n",
    "                'anomalias_if': anomaly_if_count,\n",
    "                'anomalias_lof': anomaly_lof_count,\n",
    "                'anomalias_ensemble': anomaly_ensemble_count,\n",
    "                'pontos_mudanca': change_point_count,\n",
    "                'pct_anomalias': (anomaly_ensemble_count / total_points * 100) if total_points > 0 else 0\n",
    "            })\n",
    "\n",
    "# Converter para DataFrame e exibir\n",
    "anomaly_summary_df = pd.DataFrame(anomaly_summary)\n",
    "\n",
    "# Exibir resumo global\n",
    "print(\"Resumo global de anomalias por experimento e métrica:\\n\")\n",
    "display(anomaly_summary_df[anomaly_summary_df['grupo'] == 'global'])\n",
    "\n",
    "# Criar visualização comparativa\n",
    "if not anomaly_summary_df.empty:\n",
    "    plt.figure(figsize=(14, 6))\n",
    "    \n",
    "    # Filtrar apenas estatísticas globais\n",
    "    global_stats = anomaly_summary_df[anomaly_summary_df['grupo'] == 'global']\n",
    "    \n",
    "    # Criar gráfico de barras para porcentagem de anomalias por experimento e métrica\n",
    "    sns.barplot(x='experimento', y='pct_anomalias', hue='métrica', data=global_stats)\n",
    "    plt.title('Porcentagem de Anomalias por Experimento')\n",
    "    plt.ylabel('% de Pontos Anômalos')\n",
    "    plt.xlabel('Experimento')\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "345eb9e0",
   "metadata": {},
   "source": [
    "## 6. Comparação de Covariância e Correlação entre Experimentos\n",
    "\n",
    "Vamos analisar e comparar as relações de covariância e correlação entre tenants em diferentes experimentos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c97527c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcular e comparar matrizes de covariância\n",
    "for exp_name, exp_data in experiments.items():\n",
    "    print(f\"\\n{'-'*20} Matrizes de Covariância/Correlação para {exp_name} {'-'*20}\\n\")\n",
    "    \n",
    "    for metric in metrics_of_interest:\n",
    "        if metric in exp_data['processed_metrics']:\n",
    "            print(f\"\\nMétrica: {metric}\")\n",
    "            \n",
    "            # Organizar dados para cálculo de covariância\n",
    "            metrics_dict = {metric: exp_data['processed_metrics'][metric]}\n",
    "            \n",
    "            try:\n",
    "                # Calcular matrizes\n",
    "                cov_matrix, corr_matrix = calculate_covariance_matrix(\n",
    "                    metrics_dict,\n",
    "                    tenants=None,  # Usar todos os tenants disponíveis\n",
    "                    phase=None,    # Usar todas as fases\n",
    "                    round_name=exp_data['processed_metrics'][metric]['round'].iloc[0]  # Usar primeiro round disponível\n",
    "                )\n",
    "                \n",
    "                # Exibir matrizes\n",
    "                print(\"\\nMatriz de Correlação:\")\n",
    "                display(corr_matrix)\n",
    "                \n",
    "                # Visualizar matriz de correlação como heatmap\n",
    "                plt.figure(figsize=(10, 8))\n",
    "                sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', \n",
    "                           vmin=-1, vmax=1, fmt='.2f', linewidths=0.5)\n",
    "                plt.title(f'Matriz de Correlação - {metric} ({exp_name})')\n",
    "                plt.tight_layout()\n",
    "                plt.show()\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"Erro ao calcular matrizes: {str(e)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30eb9d47",
   "metadata": {},
   "source": [
    "## 7. Visualização Comparativa de Séries Temporais\n",
    "\n",
    "Vamos criar visualizações para comparar diretamente as séries temporais de diferentes experimentos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35ff8118",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função para comparar séries temporais entre experimentos\n",
    "def compare_time_series(experiments, metric, tenant=None, phase=None):\n",
    "    plt.figure(figsize=(14, 8))\n",
    "    \n",
    "    # Organizar dados para plotagem\n",
    "    for exp_name, exp_data in experiments.items():\n",
    "        if metric in exp_data['processed_metrics']:\n",
    "            df = exp_data['processed_metrics'][metric]\n",
    "            \n",
    "            # Filtrar por tenant ou fase se especificados\n",
    "            if tenant:\n",
    "                df = df[df['tenant'] == tenant]\n",
    "            if phase:\n",
    "                df = df[df['phase'] == phase]\n",
    "            \n",
    "            # Verificar se temos dados após filtragem\n",
    "            if not df.empty:\n",
    "                plt.plot(df['elapsed_minutes'], df['value'], label=exp_name, alpha=0.7)\n",
    "    \n",
    "    plt.title(f'Comparação de {metric}' + \n",
    "             (f' para {tenant}' if tenant else '') + \n",
    "             (f' na fase {phase}' if phase else ''))\n",
    "    plt.xlabel('Tempo Decorrido (minutos)')\n",
    "    plt.ylabel('Valor')\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1be8ae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparar séries temporais para cada métrica\n",
    "for metric in metrics_of_interest:\n",
    "    print(f\"\\n{'-'*40} Comparação Temporal de {metric} {'-'*40}\\n\")\n",
    "    \n",
    "    # Comparação global\n",
    "    print(\"\\nComparação global:\")\n",
    "    compare_time_series(experiments, metric)\n",
    "    \n",
    "    # Comparação para tenant específico (se houver dados comuns)\n",
    "    if common_tenants:\n",
    "        print(f\"\\nComparação para tenant {common_tenants[0]}:\")\n",
    "        compare_time_series(experiments, metric, tenant=common_tenants[0])\n",
    "    \n",
    "    # Comparação para fase específica (se houver dados comuns)\n",
    "    if common_phases:\n",
    "        print(f\"\\nComparação para fase {common_phases[0]}:\")\n",
    "        compare_time_series(experiments, metric, phase=common_phases[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2178aca7",
   "metadata": {},
   "source": [
    "## 8. Análise de Entropia e Informação Mútua entre Experimentos\n",
    "\n",
    "Vamos calcular e comparar métricas de entropia cruzada e informação mútua entre tenants para diferentes experimentos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9433f2d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcular métricas de entropia para cada experimento\n",
    "entropy_results = {}\n",
    "\n",
    "for exp_name, exp_data in experiments.items():\n",
    "    entropy_results[exp_name] = {}\n",
    "    \n",
    "    for metric in metrics_of_interest:\n",
    "        if metric in exp_data['processed_metrics']:\n",
    "            df = exp_data['processed_metrics'][metric]\n",
    "            \n",
    "            # Calcular métricas de entropia\n",
    "            try:\n",
    "                entropy_df = calculate_entropy_metrics(\n",
    "                    df,\n",
    "                    tenants=None,  # Usar todos os tenants disponíveis\n",
    "                    phase=None,    # Usar todas as fases\n",
    "                    metric_column='value'\n",
    "                )\n",
    "                \n",
    "                entropy_results[exp_name][metric] = entropy_df\n",
    "            except Exception as e:\n",
    "                print(f\"Erro ao calcular entropia para {metric} em {exp_name}: {str(e)}\")\n",
    "                entropy_results[exp_name][metric] = pd.DataFrame()\n",
    "\n",
    "# Exibir e comparar resultados\n",
    "for metric in metrics_of_interest:\n",
    "    print(f\"\\n{'-'*40} Comparação de Entropia e Informação Mútua - {metric} {'-'*40}\\n\")\n",
    "    \n",
    "    results_to_compare = []\n",
    "    \n",
    "    for exp_name, metrics_results in entropy_results.items():\n",
    "        if metric in metrics_results and not metrics_results[metric].empty:\n",
    "            # Adicionar coluna de experimento\n",
    "            df = metrics_results[metric].copy()\n",
    "            df['experimento'] = exp_name\n",
    "            results_to_compare.append(df)\n",
    "    \n",
    "    if results_to_compare:\n",
    "        # Consolidar resultados\n",
    "        combined_entropy = pd.concat(results_to_compare, ignore_index=True)\n",
    "        display(combined_entropy)\n",
    "        \n",
    "        # Visualizar informação mútua entre experimentos\n",
    "        plt.figure(figsize=(12, 6))\n",
    "        sns.barplot(x='tenant1', y='mutual_information', hue='experimento', data=combined_entropy)\n",
    "        plt.title(f'Comparação de Informação Mútua entre Tenants - {metric}')\n",
    "        plt.xlabel('Tenant 1')\n",
    "        plt.ylabel('Informação Mútua')\n",
    "        plt.xticks(rotation=45)\n",
    "        plt.grid(True, alpha=0.3)\n",
    "        plt.tight_layout()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70cc3f58",
   "metadata": {},
   "source": [
    "## 9. Análise Dimensional e Clustering de Experimentos\n",
    "\n",
    "Vamos usar técnicas de redução de dimensionalidade e clustering para identificar padrões e agrupar experimentos similares."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a118c9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função para extrair características dos experimentos\n",
    "def extract_experiment_features(experiments, metric):\n",
    "    features = []\n",
    "    \n",
    "    for exp_name, exp_data in experiments.items():\n",
    "        if metric in exp_data['processed_metrics']:\n",
    "            df = exp_data['processed_metrics'][metric]\n",
    "            \n",
    "            # Extrair características estatísticas\n",
    "            for tenant in df['tenant'].unique():\n",
    "                tenant_data = df[df['tenant'] == tenant]\n",
    "                \n",
    "                # Calcular estatísticas\n",
    "                mean_val = tenant_data['value'].mean()\n",
    "                std_val = tenant_data['value'].std()\n",
    "                max_val = tenant_data['value'].max()\n",
    "                min_val = tenant_data['value'].min()\n",
    "                median_val = tenant_data['value'].median()\n",
    "                skew_val = tenant_data['value'].skew()\n",
    "                kurtosis_val = tenant_data['value'].kurtosis()\n",
    "                \n",
    "                # Adicionar ao conjunto de características\n",
    "                features.append({\n",
    "                    'experimento': exp_name,\n",
    "                    'métrica': metric,\n",
    "                    'tenant': tenant,\n",
    "                    'média': mean_val,\n",
    "                    'desvio_padrão': std_val,\n",
    "                    'máximo': max_val,\n",
    "                    'mínimo': min_val,\n",
    "                    'mediana': median_val,\n",
    "                    'assimetria': skew_val,\n",
    "                    'curtose': kurtosis_val\n",
    "                })\n",
    "    \n",
    "    return pd.DataFrame(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6706a337",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extrair características para análise dimensional\n",
    "for metric in metrics_of_interest:\n",
    "    print(f\"\\n{'-'*40} Análise Dimensional para {metric} {'-'*40}\\n\")\n",
    "    \n",
    "    # Extrair características\n",
    "    features_df = extract_experiment_features(experiments, metric)\n",
    "    \n",
    "    if features_df.empty:\n",
    "        print(f\"Dados insuficientes para análise de {metric}\")\n",
    "        continue\n",
    "    \n",
    "    # Exibir características extraídas\n",
    "    print(\"Características extraídas:\")\n",
    "    display(features_df)\n",
    "    \n",
    "    # Preparar dados para PCA e t-SNE\n",
    "    numeric_features = ['média', 'desvio_padrão', 'máximo', 'mínimo', 'mediana', 'assimetria', 'curtose']\n",
    "    X = features_df[numeric_features].values\n",
    "    \n",
    "    # Normalizar dados\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "    \n",
    "    # PCA\n",
    "    if X_scaled.shape[0] > 1 and X_scaled.shape[1] > 1:\n",
    "        pca = PCA(n_components=2)\n",
    "        X_pca = pca.fit_transform(X_scaled)\n",
    "        \n",
    "        # t-SNE (se houver dados suficientes)\n",
    "        if X_scaled.shape[0] >= 5:\n",
    "            tsne = TSNE(n_components=2, random_state=42)\n",
    "            X_tsne = tsne.fit_transform(X_scaled)\n",
    "            \n",
    "            # Visualizar resultados\n",
    "            plt.figure(figsize=(16, 6))\n",
    "            \n",
    "            # PCA plot\n",
    "            plt.subplot(1, 2, 1)\n",
    "            for exp in features_df['experimento'].unique():\n",
    "                mask = features_df['experimento'] == exp\n",
    "                plt.scatter(X_pca[mask, 0], X_pca[mask, 1], label=exp, alpha=0.8, s=50)\n",
    "            \n",
    "            for i, txt in enumerate(features_df['tenant']):\n",
    "                plt.annotate(txt, (X_pca[i, 0], X_pca[i, 1]), fontsize=9)\n",
    "                \n",
    "            plt.title(f'PCA - {metric}')\n",
    "            plt.xlabel(f'PC1 ({pca.explained_variance_ratio_[0]*100:.2f}%)')\n",
    "            plt.ylabel(f'PC2 ({pca.explained_variance_ratio_[1]*100:.2f}%)')\n",
    "            plt.grid(True, alpha=0.3)\n",
    "            plt.legend()\n",
    "            \n",
    "            # t-SNE plot\n",
    "            plt.subplot(1, 2, 2)\n",
    "            for exp in features_df['experimento'].unique():\n",
    "                mask = features_df['experimento'] == exp\n",
    "                plt.scatter(X_tsne[mask, 0], X_tsne[mask, 1], label=exp, alpha=0.8, s=50)\n",
    "            \n",
    "            for i, txt in enumerate(features_df['tenant']):\n",
    "                plt.annotate(txt, (X_tsne[i, 0], X_tsne[i, 1]), fontsize=9)\n",
    "                \n",
    "            plt.title(f't-SNE - {metric}')\n",
    "            plt.xlabel('Dimensão 1')\n",
    "            plt.ylabel('Dimensão 2')\n",
    "            plt.grid(True, alpha=0.3)\n",
    "            plt.legend()\n",
    "            \n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "        else:\n",
    "            # Apenas PCA se não houver dados suficientes para t-SNE\n",
    "            plt.figure(figsize=(8, 6))\n",
    "            for exp in features_df['experimento'].unique():\n",
    "                mask = features_df['experimento'] == exp\n",
    "                plt.scatter(X_pca[mask, 0], X_pca[mask, 1], label=exp, alpha=0.8, s=50)\n",
    "            \n",
    "            for i, txt in enumerate(features_df['tenant']):\n",
    "                plt.annotate(txt, (X_pca[i, 0], X_pca[i, 1]), fontsize=9)\n",
    "                \n",
    "            plt.title(f'PCA - {metric}')\n",
    "            plt.xlabel(f'PC1 ({pca.explained_variance_ratio_[0]*100:.2f}%)')\n",
    "            plt.ylabel(f'PC2 ({pca.explained_variance_ratio_[1]*100:.2f}%)')\n",
    "            plt.grid(True, alpha=0.3)\n",
    "            plt.legend()\n",
    "            plt.tight_layout()\n",
    "            plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47a25f05",
   "metadata": {},
   "source": [
    "## 10. Conclusões e Próximos Passos\n",
    "\n",
    "Este notebook demonstrou como comparar diferentes experimentos de noisy neighbors para identificar padrões, diferenças e semelhanças entre eles. As principais análises realizadas incluíram:\n",
    "\n",
    "1. **Comparação de estatísticas básicas**: média, mediana, desvio padrão, etc.\n",
    "2. **Comparação de distribuições**: usando boxplots, violin plots e testes estatísticos\n",
    "3. **Comparação de anomalias**: análise da prevalência e tipos de anomalias entre experimentos\n",
    "4. **Análise de covariância e correlação**: comparação das relações entre tenants\n",
    "5. **Visualização comparativa de séries temporais**: sobreposição direta das métricas\n",
    "6. **Análise de entropia e informação mútua**: comparação de interdependências entre tenants\n",
    "7. **Análise dimensional**: uso de PCA e t-SNE para visualizar e agrupar características\n",
    "\n",
    "### Próximos Passos:\n",
    "\n",
    "- Expandir as comparações para incluir mais experimentos com diferentes configurações\n",
    "- Desenvolver métricas de similaridade entre experimentos\n",
    "- Implementar análises estatísticas mais avançadas para quantificar diferenças\n",
    "- Integrar com o módulo de geração de relatórios para documentação automática\n",
    "- Utilizar técnicas de aprendizado de máquina para prever resultados de novos experimentos com base nos existentes\n",
    "- Criar um framework para avaliar o impacto de diferentes estratégias de mitigação de interferência entre tenants"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
